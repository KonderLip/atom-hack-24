{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa75ba80-a1bd-484f-b4fc-91d9859b7fc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T07:09:22.916800Z",
     "iopub.status.busy": "2024-11-10T07:09:22.915190Z",
     "iopub.status.idle": "2024-11-10T07:09:36.217811Z",
     "shell.execute_reply": "2024-11-10T07:09:36.215886Z",
     "shell.execute_reply.started": "2024-11-10T07:09:22.916763Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "import docx\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "from prompts import prompt, system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de75cde-5c3f-4277-85f4-04719ab71887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T07:09:36.225642Z",
     "iopub.status.busy": "2024-11-10T07:09:36.221681Z",
     "iopub.status.idle": "2024-11-10T07:09:36.247893Z",
     "shell.execute_reply": "2024-11-10T07:09:36.246523Z",
     "shell.execute_reply.started": "2024-11-10T07:09:36.225554Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_test = \"./test data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9cd90d-b9a9-47fe-9b67-96ba650a4b20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T07:09:36.249878Z",
     "iopub.status.busy": "2024-11-10T07:09:36.249153Z",
     "iopub.status.idle": "2024-11-10T07:09:36.270938Z",
     "shell.execute_reply": "2024-11-10T07:09:36.269630Z",
     "shell.execute_reply.started": "2024-11-10T07:09:36.249814Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[114671,\n",
       " 259571,\n",
       " 259572,\n",
       " 261611,\n",
       " 29448,\n",
       " 30364,\n",
       " 30365,\n",
       " 30370,\n",
       " 315231,\n",
       " 65831,\n",
       " 65832,\n",
       " 65833,\n",
       " 86921,\n",
       " 88001,\n",
       " 88002]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [int(file.split('.')[0].split('-')[1]) for file in os.listdir(f\"{path_to_test}/HMI/\")]\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4f8fc7-86cf-47ce-9faa-4c3aed3fc1ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T07:09:36.274653Z",
     "iopub.status.busy": "2024-11-10T07:09:36.273588Z",
     "iopub.status.idle": "2024-11-10T07:09:36.294872Z",
     "shell.execute_reply": "2024-11-10T07:09:36.293760Z",
     "shell.execute_reply.started": "2024-11-10T07:09:36.274588Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "name2cls = {\n",
    "    \"Fully compliant\": \"FC\",\n",
    "    \"Largely compliant\": \"LC\",\n",
    "    \"Partially compliant\": \"PC\",\n",
    "    \"Not compliant\": \"NC\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52712999-f3a0-4062-bbcb-723f9d649115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T07:09:36.297152Z",
     "iopub.status.busy": "2024-11-10T07:09:36.295930Z",
     "iopub.status.idle": "2024-11-10T07:09:51.479312Z",
     "shell.execute_reply": "2024-11-10T07:09:51.478138Z",
     "shell.execute_reply.started": "2024-11-10T07:09:36.297094Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.9.post4: Fast Mistral patching. Transformers = 4.46.2.\n",
      "   \\\\   /|    GPU: Tesla V100-PCIE-32GB. Max memory: 31.739 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.2.0+cu121. CUDA = 7.0. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.24+cu118. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 615.86it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]\n",
      "Unsloth 2024.9.post4 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# загружаем дообученную модель\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"./Mistral-finetuned\",\n",
    "    max_seq_length=2048,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "168399ac-31c0-4026-a462-f1148b42a89b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T07:09:51.481649Z",
     "iopub.status.busy": "2024-11-10T07:09:51.480597Z",
     "iopub.status.idle": "2024-11-10T07:09:51.515774Z",
     "shell.execute_reply": "2024-11-10T07:09:51.514740Z",
     "shell.execute_reply.started": "2024-11-10T07:09:51.481589Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(131072, 5120)\n",
       "        (layers): ModuleList(\n",
       "          (0-39): 40 x MistralDecoderLayer(\n",
       "            (self_attn): MistralAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5120, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=5120, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=5120, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5120, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5120, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=5120, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=5120, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm((5120,), eps=1e-05)\n",
       "            (post_attention_layernorm): MistralRMSNorm((5120,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm((5120,), eps=1e-05)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=5120, out_features=131072, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089c7f62-04d2-4869-ac93-ce5985af54bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T07:09:51.517933Z",
     "iopub.status.busy": "2024-11-10T07:09:51.517056Z",
     "iopub.status.idle": "2024-11-10T07:09:51.591391Z",
     "shell.execute_reply": "2024-11-10T07:09:51.590100Z",
     "shell.execute_reply.started": "2024-11-10T07:09:51.517884Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_differences(name, uc_text, ssts_text):\n",
    "    inputs = tokenizer([prompt.format(system[\"Differences\"], name, uc_text, ssts_text, \"Differences\", \"\")], return_tensors = \"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=128, use_cache=True)\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return result.split(\"### Differences:\")[-1].strip()\n",
    "\n",
    "def get_description(name, uc_text, ssts_text):\n",
    "    inputs = tokenizer([prompt.format(system[\"Description\"], name, uc_text, ssts_text, \"Description\", \"\")], return_tensors = \"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=128, use_cache=True)\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return result.split(\"### Description:\")[-1].strip()\n",
    "\n",
    "def get_cls(name, uc_text, ssts_text):\n",
    "    inputs = tokenizer([prompt.format(system[\"Complience Level\"], name, uc_text, ssts_text, \"Complience Level\", \"\")], return_tensors = \"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=128, use_cache=True)\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return name2cls[result.split(\"### Complience Level:\")[-1].strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70211b3d-256a-4517-b6f4-90cf850f00cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T07:09:51.594122Z",
     "iopub.status.busy": "2024-11-10T07:09:51.592821Z",
     "iopub.status.idle": "2024-11-10T07:13:59.728811Z",
     "shell.execute_reply": "2024-11-10T07:13:59.727637Z",
     "shell.execute_reply.started": "2024-11-10T07:09:51.594069Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:08<00:00, 16.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 6s, sys: 2.17 s, total: 4min 8s\n",
      "Wall time: 4min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "submit = []\n",
    "for number in tqdm(numbers):\n",
    "    uc_doc = docx.Document(f\"{path_to_test}/HMI/UC-{number}.docx\")\n",
    "    uc_text = \"\\n\".join(paragraph.text for paragraph in uc_doc.paragraphs[1:])\n",
    "    name = uc_doc.paragraphs[0].text.split('\\xa0')[-1].strip()\n",
    "    \n",
    "    if not os.path.exists(f\"{path_to_test}/SSTS/SSTS-{number}.docx\"):\n",
    "        submit.append({\n",
    "            \"Number\": number,\n",
    "            \"Name\": name,\n",
    "            \"Differences\": \"ssts hasn't info about this\",\n",
    "            \"Description\": \"-\",\n",
    "            \"Complience Level\": \"NA\"\n",
    "        })\n",
    "        continue\n",
    "        \n",
    "    ssts_doc = docx.Document(f\"{path_to_test}/SSTS/SSTS-{number}.docx\")\n",
    "    ssts_text = \"\\n\".join(paragraph.text for paragraph in ssts_doc.paragraphs[1:])\n",
    "    \n",
    "    submit.append({\n",
    "        \"Number\": number,\n",
    "        \"Name\": name,\n",
    "        \"Differences\": get_differences(name, uc_text, ssts_text),\n",
    "        \"Description\": get_description(name, uc_text, ssts_text),\n",
    "        \"Complience Level\": get_cls(name, uc_text, ssts_text)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7878fd3c",
   "metadata": {},
   "source": [
    "скорость 16.54s на итерацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff334db3-4062-4b14-ab54-639074a9eb5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T07:13:59.731805Z",
     "iopub.status.busy": "2024-11-10T07:13:59.730272Z",
     "iopub.status.idle": "2024-11-10T07:13:59.757748Z",
     "shell.execute_reply": "2024-11-10T07:13:59.756615Z",
     "shell.execute_reply.started": "2024-11-10T07:13:59.731722Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Name</th>\n",
       "      <th>Differences</th>\n",
       "      <th>Description</th>\n",
       "      <th>Complience Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114671</td>\n",
       "      <td>Revoke access to the vehicle from a driver or ...</td>\n",
       "      <td>No differences</td>\n",
       "      <td>The driver opens the ATOM application on his i...</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259571</td>\n",
       "      <td>Mute/unmute the FM Radio playback</td>\n",
       "      <td>There is no soft button icon and description i...</td>\n",
       "      <td>The user clicks on the radio and clicks on the...</td>\n",
       "      <td>LC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259572</td>\n",
       "      <td>Mute/unmute the FM Radio playback</td>\n",
       "      <td>There is no soft button icon and description i...</td>\n",
       "      <td>The user clicks on the radio and clicks on the...</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>261611</td>\n",
       "      <td>FM Radio Stations switching</td>\n",
       "      <td>No online music playback page on in_5.\\nNo net...</td>\n",
       "      <td>Users can switch the next/previous FM Radio st...</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29448</td>\n",
       "      <td>Configure heat preservation</td>\n",
       "      <td>No online&amp;offline mode.</td>\n",
       "      <td>Users can configure heat preservation via in_2...</td>\n",
       "      <td>LC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number                                               Name  \\\n",
       "0  114671  Revoke access to the vehicle from a driver or ...   \n",
       "1  259571                  Mute/unmute the FM Radio playback   \n",
       "2  259572                  Mute/unmute the FM Radio playback   \n",
       "3  261611                        FM Radio Stations switching   \n",
       "4   29448                        Configure heat preservation   \n",
       "\n",
       "                                         Differences  \\\n",
       "0                                     No differences   \n",
       "1  There is no soft button icon and description i...   \n",
       "2  There is no soft button icon and description i...   \n",
       "3  No online music playback page on in_5.\\nNo net...   \n",
       "4                            No online&offline mode.   \n",
       "\n",
       "                                         Description Complience Level  \n",
       "0  The driver opens the ATOM application on his i...               NC  \n",
       "1  The user clicks on the radio and clicks on the...               LC  \n",
       "2  The user clicks on the radio and clicks on the...               NC  \n",
       "3  Users can switch the next/previous FM Radio st...               NC  \n",
       "4  Users can configure heat preservation via in_2...               LC  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.DataFrame(submit)\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "687f6b51-c2a2-4413-8ba6-e1fe4ad7086e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T07:13:59.761249Z",
     "iopub.status.busy": "2024-11-10T07:13:59.760415Z",
     "iopub.status.idle": "2024-11-10T07:13:59.782947Z",
     "shell.execute_reply": "2024-11-10T07:13:59.781966Z",
     "shell.execute_reply.started": "2024-11-10T07:13:59.761200Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LC    11\n",
       "NC     4\n",
       "Name: Complience Level, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit[\"Complience Level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63b4a74b-7a7c-4c04-b221-265750bb0576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T07:13:59.785553Z",
     "iopub.status.busy": "2024-11-10T07:13:59.784022Z",
     "iopub.status.idle": "2024-11-10T07:13:59.810415Z",
     "shell.execute_reply": "2024-11-10T07:13:59.809321Z",
     "shell.execute_reply.started": "2024-11-10T07:13:59.785510Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
